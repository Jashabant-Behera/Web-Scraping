{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. COST CONSIDERATIONS\n",
    "\n",
    "### Definition\n",
    "**Building ML systems is expensive**. Often prohibitively so for small organizations.\n",
    "\n",
    "### Cost Breakdown:\n",
    "\n",
    "```\n",
    "ML Project Budget = Data + Computing + Personnel + Infrastructure\n",
    "\n",
    "1. DATA COLLECTION & LABELING\n",
    "   \u251c\u2500 Data acquisition: $1K - $100K\n",
    "   \u251c\u2500 Manual labeling: $10K - $1M\n",
    "   \u2502  \u2514\u2500 Depends on: Volume, Complexity, Expertise needed\n",
    "   \u251c\u2500 Crowdsourcing: $1K - $100K\n",
    "   \u2514\u2500 Annotation tools: $100 - $10K/month\n",
    "\n",
    "2. COMPUTING RESOURCES\n",
    "   \u251c\u2500 GPU/TPU for training: $1K - $100K/month\n",
    "   \u251c\u2500 Storage: $100 - $10K/month\n",
    "   \u251c\u2500 Cloud platform: $1K - $50K/month\n",
    "   \u2502  \u2514\u2500 AWS, GCP, Azure compute costs\n",
    "   \u2514\u2500 Infrastructure: $5K - $100K (setup)\n",
    "\n",
    "3. PERSONNEL\n",
    "   \u251c\u2500 Data scientists: $80K - $200K/year (1-3 people)\n",
    "   \u251c\u2500 ML engineers: $100K - $250K/year (1-2 people)\n",
    "   \u251c\u2500 Data engineers: $90K - $220K/year (1-2 people)\n",
    "   \u2514\u2500 ML Ops: $80K - $200K/year (1 person)\n",
    "\n",
    "4. TOTAL FIRST YEAR: $200K - $2M+\n",
    "\n",
    "5. ONGOING (PER YEAR): $150K - $1M\n",
    "   \u251c\u2500 Salaries\n",
    "   \u251c\u2500 Computing\n",
    "   \u251c\u2500 Data updates\n",
    "   \u2514\u2500 Maintenance\n",
    "```\n",
    "\n",
    "### Real-World Cost Examples:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Image Classification for E-commerce\n",
    "# Objective: Categorize 1M product images\n",
    "\n",
    "# Cost Breakdown:\n",
    "costs = {\n",
    "    'Manual annotation': 1_000_000 * 0.50,      # $500K (0.50 per image)\n",
    "    'AWS S3 storage': (1_000_000 * 5e-6 * 365),  # $1.8K/year\n",
    "    'GPU training (1 month)': 30 * 24 * 2.4,     # $1.7K\n",
    "    'Data scientist (6 months)': 150_000 * 0.5,  # $75K\n",
    "    'ML engineer (6 months)': 200_000 * 0.5,     # $100K\n",
    "}\n",
    "\n",
    "total = sum(costs.values())\n",
    "print(f\"Total cost: ${total:,.0f}\")\n",
    "# \u2192 ~$677K for 1M images\n",
    "\n",
    "# Example 2: NLP Model for Customer Support\n",
    "# Objective: Classify 100K support tickets\n",
    "\n",
    "costs_nlp = {\n",
    "    'Crowdsourced labeling': 100_000 * 0.10,    # $10K\n",
    "    'Compute (training)': 5 * 3600 * 0.30,      # $5.4K\n",
    "    'Data scientist (3 months)': 150_000 * 0.25, # $37.5K\n",
    "}\n",
    "\n",
    "total_nlp = sum(costs_nlp.values())\n",
    "print(f\"Total cost: ${total_nlp:,.0f}\")\n",
    "# \u2192 ~$52.9K for 100K tickets\n",
    "\n",
    "# Example 3: Autonomous Vehicle ML System\n",
    "# Objective: Detect pedestrians, cars, signs in video\n",
    "\n",
    "costs_av = {\n",
    "    'Video data collection': 100_000,            # $100K\n",
    "    'Manual annotation': 1_000_000 * 5,          # $5M (expensive)\n",
    "    'GPU cluster (1 year)': 100 * 24 * 365 * 0.30,  # $262K\n",
    "    'Team (5 people, 1 year)': (150 + 200 + 90 + 100 + 80) * 1000,  # $620K\n",
    "}\n",
    "\n",
    "total_av = sum(costs_av.values())\n",
    "print(f\"Total cost: ${total_av:,.0f}\")\n",
    "# \u2192 ~$5.98M per year!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Optimization Strategies:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy 1: Use existing models (Transfer Learning)\n",
    "# Instead of: Train from scratch ($500K)\n",
    "# Do: Fine-tune pre-trained model ($50K)\n",
    "# Savings: $450K\n",
    "\n",
    "from transformers import AutoModel\n",
    "\n",
    "# Pre-trained BERT (millions of dollars already spent by others)\n",
    "model = AutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Fine-tune on your specific task\n",
    "model.fit(your_data, your_labels, epochs=5)\n",
    "\n",
    "# Cost: Only fine-tuning, not pre-training!\n",
    "\n",
    "# Strategy 2: Data augmentation instead of collecting more\n",
    "# Instead of: Collect 100K images ($50K)\n",
    "# Do: Augment 10K images ($5K)\n",
    "# Savings: $45K\n",
    "\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "aug = iaa.Sequential([\n",
    "    iaa.Fliplr(0.5),\n",
    "    iaa.Affine(rotate=(-25, 25)),\n",
    "    iaa.Multiply((0.8, 1.2)),\n",
    "    iaa.GaussianBlur(sigma=(0, 0.5))\n",
    "])\n",
    "\n",
    "# Create 10 augmented versions of each image\n",
    "augmented_images = []\n",
    "for img in original_images:\n",
    "    for _ in range(10):\n",
    "        augmented_images.append(aug(image=img))\n",
    "\n",
    "# 10K \u2192 100K images cheaply!\n",
    "\n",
    "# Strategy 3: Automated labeling + human validation\n",
    "# Instead of: Manual label all 100K samples ($10K)\n",
    "# Do: Auto-label + human verify 10% ($1K labeling + $1K review)\n",
    "# Savings: $8K\n",
    "\n",
    "def auto_label_with_heuristics(data):\n",
    "    \"\"\"Quick automated labeling using rules\"\"\"\n",
    "    labels = []\n",
    "    for item in data:\n",
    "        if 'negative_word' in item.text:\n",
    "            labels.append('negative')\n",
    "        elif 'positive_word' in item.text:\n",
    "            labels.append('positive')\n",
    "        else:\n",
    "            labels.append('uncertain')\n",
    "    return labels\n",
    "\n",
    "# Auto-label all\n",
    "auto_labels = auto_label_with_heuristics(data)\n",
    "\n",
    "# Humans verify uncertain ones (small set)\n",
    "uncertain_indices = [i for i, l in enumerate(auto_labels) if l == 'uncertain']\n",
    "human_verified = human_review(uncertain_indices)\n",
    "\n",
    "# Low cost, decent quality!\n",
    "\n",
    "# Strategy 4: Prioritize high-impact use cases\n",
    "# Focus on:\n",
    "# - High revenue impact ($)\n",
    "# - Easy to implement (low cost)\n",
    "# - High success probability (ROI)\n",
    "\n",
    "# Not all ML projects are worthwhile!\n",
    "impact_assessment = pd.DataFrame({\n",
    "    'Use Case': ['Recommendation', 'Price Optimization', 'Churn Prediction'],\n",
    "    'Annual Impact': [1_000_000, 500_000, 200_000],\n",
    "    'Development Cost': [300_000, 100_000, 50_000],\n",
    "    'ROI': [1_000_000 / 300_000, 500_000 / 100_000, 200_000 / 50_000]\n",
    "})\n",
    "\n",
    "# Sort by ROI, focus on highest\n",
    "impact_assessment = impact_assessment.sort_values('ROI', ascending=False)\n",
    "\n",
    "# Strategy 5: Use AutoML to reduce data scientist costs\n",
    "from h2o import automl\n",
    "\n",
    "# Instead of hiring expensive data scientist\n",
    "# Use automated ML to:\n",
    "# - Feature engineering\n",
    "# - Model selection\n",
    "# - Hyperparameter tuning\n",
    "\n",
    "# Cost: $50/month for AutoML platform\n",
    "# vs. $150K/year for data scientist\n",
    "\n",
    "h2o.init()\n",
    "aml = automl.H2OAutoML(max_models=20, seed=1)\n",
    "aml.train(X=X, y=y, training_frame=train)\n",
    "\n",
    "# Saves ~$140K/year!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When NOT to Build ML Models:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \u274c Don't build if:\n",
    "\n",
    "# 1. Simple rules work better\n",
    "# Instead of ML: if age > 50 and income > 100K: approve\n",
    "# Rule: $0, Accuracy: 90%\n",
    "\n",
    "# 2. Data doesn't exist\n",
    "# Can't build recommendation without user history\n",
    "# Collect data first\n",
    "\n",
    "# 3. ROI negative\n",
    "# Cost: $500K, Expected benefit: $100K\n",
    "# ROI = -80%, DON'T BUILD\n",
    "\n",
    "# 4. Regulation/ethics issues\n",
    "# Discriminatory models\n",
    "# Privacy violations\n",
    "# Regulatory non-compliance\n",
    "\n",
    "# 5. Real-time predictions not needed\n",
    "# Use business rules or simpler models\n",
    "# Save $300K on infrastructure\n",
    "\n",
    "# 6. Data quality too poor\n",
    "# 80% missing values, 50% errors\n",
    "# Fix data first (cheaper)\n",
    "\n",
    "# \u2705 Do build if:\n",
    "# 1. High ROI (>300%)\n",
    "# 2. Data readily available\n",
    "# 3. Complex patterns to learn\n",
    "# 4. Real-time predictions needed\n",
    "# 5. Ethical/regulatory OK\n",
    "# 6. Team has expertise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Estimation Framework:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_ml_project_cost(\n",
    "    dataset_size_samples,\n",
    "    annotation_complexity,  # 'simple', 'moderate', 'complex'\n",
    "    model_complexity,       # 'simple', 'moderate', 'complex'\n",
    "    deployment_scale        # 'small', 'medium', 'large'\n",
    "):\n",
    "    \"\"\"Estimate ML project costs\"\"\"\n",
    "    \n",
    "    # Data costs\n",
    "    annotation_costs = {\n",
    "        'simple': 0.10,\n",
    "        'moderate': 0.50,\n",
    "        'complex': 5.00\n",
    "    }\n",
    "    data_cost = dataset_size_samples * annotation_costs[annotation_complexity]\n",
    "    \n",
    "    # Computing costs (6 months)\n",
    "    compute_costs = {\n",
    "        'simple': 5_000,\n",
    "        'moderate': 30_000,\n",
    "        'complex': 100_000\n",
    "    }\n",
    "    compute_cost = compute_costs[model_complexity]\n",
    "    \n",
    "    # Personnel (6 months)\n",
    "    team_sizes = {\n",
    "        'simple': 1,        # 1 data scientist\n",
    "        'moderate': 2,      # 1 DS + 1 engineer\n",
    "        'complex': 4        # Full team\n",
    "    }\n",
    "    personnel_cost = team_sizes[model_complexity] * 75_000  # 6 months average\n",
    "    \n",
    "    # Infrastructure\n",
    "    infra_costs = {\n",
    "        'small': 10_000,\n",
    "        'medium': 50_000,\n",
    "        'large': 200_000\n",
    "    }\n",
    "    infra_cost = infra_costs[deployment_scale]\n",
    "    \n",
    "    # Total\n",
    "    total = data_cost + compute_cost + personnel_cost + infra_cost\n",
    "    \n",
    "    return {\n",
    "        'data': data_cost,\n",
    "        'compute': compute_cost,\n",
    "        'personnel': personnel_cost,\n",
    "        'infrastructure': infra_cost,\n",
    "        'total': total\n",
    "    }\n",
    "\n",
    "# Example: Medium complexity project\n",
    "costs = estimate_ml_project_cost(\n",
    "    dataset_size_samples=50_000,\n",
    "    annotation_complexity='moderate',\n",
    "    model_complexity='moderate',\n",
    "    deployment_scale='medium'\n",
    ")\n",
    "\n",
    "print(\"Cost Breakdown:\")\n",
    "for category, amount in costs.items():\n",
    "    print(f\"  {category.capitalize()}: ${amount:,.0f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## SUMMARY TABLE: ML CHALLENGES\n",
    "\n",
    "| Challenge | Problem | Impact | Solution |\n",
    "|-----------|---------|--------|----------|\n",
    "| **Data Collection** | Scraping legal/technical issues, API limits | Limited training data | Use APIs, buy datasets, crowdsource |\n",
    "| **Insufficient Data** | Can't afford labeling, annotation errors | Poor model performance | Transfer learning, data augmentation, semi-supervised learning |\n",
    "| **Non-Representative Data** | Sampling bias, not representative | Poor generalization, unfair predictions | Stratified sampling, reweighting, collect representative data |\n",
    "| **Poor Quality** | Missing values, outliers, duplicates | Model fails or performs poorly | Data cleaning, validation, quality checks |\n",
    "| **Irrelevant Features** | Noise introduced, overfitting | Worse performance | Feature selection, domain expertise |\n",
    "| **Overfitting** | Model memorizes training data | Great train, terrible test | Regularization, early stopping, more data |\n",
    "| **Underfitting** | Model too simple | Poor performance everywhere | More complex model, feature engineering |\n",
    "| **Integration** | Env mismatch, deployment challenges | Model fails in production | Containerization, CI/CD, monitoring |\n",
    "| **Offline Learning** | Concept drift, model becomes stale | Predictions degrade over time | Online learning, scheduled retraining |\n",
    "| **Cost** | High data/compute/personnel costs | Project infeasible | Use transfer learning, AutoML, cost-benefit analysis |\n",
    "\n",
    "---\n",
    "\n",
    "## PRACTICAL CHECKLIST: Avoiding ML Challenges\n",
    "\n",
    "### Before Starting:\n",
    "- [ ] Understand business requirements and ROI\n",
    "- [ ] Assess data availability and quality\n",
    "- [ ] Check if ML is necessary (rules might work)\n",
    "- [ ] Estimate costs (data + compute + team)\n",
    "- [ ] Understand ethical/regulatory implications\n",
    "\n",
    "### Data Collection:\n",
    "- [ ] Use APIs when available (legal, reliable)\n",
    "- [ ] Respect ToS and robots.txt\n",
    "- [ ] Ensure data is representative\n",
    "- [ ] Validate data quality early\n",
    "- [ ] Plan for continuous data collection\n",
    "\n",
    "### Model Development:\n",
    "- [ ] Start with simple baselines\n",
    "- [ ] Monitor for overfitting/underfitting\n",
    "- [ ] Use cross-validation\n",
    "- [ ] Perform feature selection\n",
    "- [ ] Document everything\n",
    "\n",
    "### Deployment:\n",
    "- [ ] Containerize model (Docker)\n",
    "- [ ] Set up logging and monitoring\n",
    "- [ ] Plan for model updates\n",
    "- [ ] Implement A/B testing\n",
    "- [ ] Have rollback plan\n",
    "\n",
    "### Production:\n",
    "- [ ] Monitor data drift\n",
    "- [ ] Track model performance\n",
    "- [ ] Retrain on schedule\n",
    "- [ ] Handle edge cases\n",
    "- [ ] Maintain documentation\n",
    "\n",
    "---\n",
    "\n",
    "**Use these notes as reference for identifying and solving real-world ML challenges!**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}