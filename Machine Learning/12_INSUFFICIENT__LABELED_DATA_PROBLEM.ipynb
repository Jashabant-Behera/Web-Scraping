{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. INSUFFICIENT / LABELED DATA PROBLEM\n",
    "\n",
    "### Definition\n",
    "**Not having enough labeled training data** is one of the biggest challenges in supervised learning.\n",
    "\n",
    "### The Challenge\n",
    "\n",
    "#### How Much Data Do You Need?\n",
    "```\n",
    "Simple models (Linear Regression):      100 - 1,000 samples\n",
    "Medium models (Decision Trees):         1,000 - 10,000 samples\n",
    "Complex models (Neural Networks):       10,000 - 1,000,000 samples\n",
    "Deep Learning (Images, Text, Audio):    1,000,000+ samples\n",
    "```\n",
    "\n",
    "#### The Chicken-and-Egg Problem:\n",
    "- Need data to train models\n",
    "- Need models to label data\n",
    "- Labeling is expensive and time-consuming\n",
    "- Manual labeling: $0.10 - $10+ per sample (domain-dependent)\n",
    "\n",
    "### Real Numbers:\n",
    "```\n",
    "Labeling Cost Examples:\n",
    "- Image classification: $1-5 per image\n",
    "- Medical imaging: $10-50 per image\n",
    "- Text annotation: $0.10-1 per sample\n",
    "- Video labeling: $50+ per hour\n",
    "\n",
    "Dataset Size Costs:\n",
    "- 1,000 samples: $100 - $50,000\n",
    "- 10,000 samples: $1,000 - $500,000\n",
    "- 100,000 samples: $10,000 - $5,000,000\n",
    "- 1,000,000 samples: Millions of dollars\n",
    "```\n",
    "\n",
    "### 2.1 Manual Labeling Challenges\n",
    "\n",
    "#### Inconsistencies Between Annotators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Inter-rater disagreement\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, cohen_kappa_score\n",
    "\n",
    "# Annotator 1's labels\n",
    "annotator1 = np.array([0, 1, 1, 0, 1, 0, 1, 1, 0, 1])\n",
    "\n",
    "# Annotator 2's labels (same samples)\n",
    "annotator2 = np.array([0, 1, 0, 0, 1, 1, 1, 1, 0, 0])\n",
    "\n",
    "# Measure disagreement\n",
    "disagreement = np.sum(annotator1 != annotator2) / len(annotator1)\n",
    "print(f\"Disagreement rate: {disagreement*100:.1f}%\")  # 30%!\n",
    "\n",
    "# Calculate Cohen's Kappa (agreement beyond chance)\n",
    "kappa = cohen_kappa_score(annotator1, annotator2)\n",
    "print(f\"Cohen's Kappa: {kappa:.2f}\")  # 0.56 (moderate agreement)\n",
    "\n",
    "# Confusion between annotators\n",
    "cm = confusion_matrix(annotator1, annotator2)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ambiguous Cases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Ambiguous sentiment classification\n",
    "texts = [\n",
    "    \"This movie is not bad\",           # Sarcasm? Negative or Positive?\n",
    "    \"I love this... not\",              # Sarcasm? Confusing!\n",
    "    \"It's okay, I guess\",              # Slightly positive or negative?\n",
    "    \"This product broke after 1 day\",  # Clear negative\n",
    "    \"Great quality! Expensive though\",  # Mixed positive/negative\n",
    "]\n",
    "\n",
    "# Different annotators might label differently\n",
    "# Text 1: A says negative, B says positive \u2192 Disagreement!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Solutions to Insufficient Data\n",
    "\n",
    "#### 1. Data Augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Images\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Artificial variations of existing images\n",
    "augment = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# For Text\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.sentence as nas\n",
    "\n",
    "# Synonym replacement\n",
    "text = \"The movie is great\"\n",
    "augment = naw.SynonymAug(aug_src='wordnet')\n",
    "augmented = augment.augment(text)\n",
    "# Might produce: \"The film is wonderful\"\n",
    "\n",
    "# Paraphrasing\n",
    "augment = nas.ContextualWordEmbsAug(\n",
    "    model_path='bert-base-uncased',\n",
    "    action=\"substitute\"\n",
    ")\n",
    "\n",
    "# For Structured Data\n",
    "def augment_numerical_data(X, noise_level=0.1):\n",
    "    import numpy as np\n",
    "    noise = np.random.normal(0, noise_level, X.shape)\n",
    "    return X + noise\n",
    "\n",
    "# Example: 100 samples \u2192 1000 samples through augmentation\n",
    "original_data = np.random.rand(100, 20)\n",
    "augmented_data = []\n",
    "\n",
    "for _ in range(10):  # 10x augmentation\n",
    "    augmented_data.append(augment_numerical_data(original_data))\n",
    "\n",
    "augmented_data = np.vstack(augmented_data)\n",
    "print(f\"Original: {original_data.shape}, Augmented: {augmented_data.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Transfer Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pre-trained models instead of training from scratch\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Pre-trained on millions of images\n",
    "base_model = MobileNetV2(\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'  # Pre-trained weights\n",
    ")\n",
    "\n",
    "# Freeze base model weights (don't retrain)\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add small custom layer on top\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(10, activation='softmax')  # Your classes\n",
    "])\n",
    "\n",
    "# Train only your custom layers (requires less data!)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "model.fit(your_limited_data, epochs=10)\n",
    "\n",
    "# With transfer learning:\n",
    "# - Only need 100s of samples instead of 100,000s\n",
    "# - Trains 10x faster\n",
    "# - Better accuracy with limited data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Semi-Supervised Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use both labeled and unlabeled data\n",
    "from sklearn.semi_supervised import LabelSpreading\n",
    "import numpy as np\n",
    "\n",
    "# Labeled data (expensive)\n",
    "X_labeled = np.array([[1, 0], [0, 1], [1, 1]])\n",
    "y_labeled = np.array([0, 1, 1])\n",
    "\n",
    "# Unlabeled data (cheap, abundant)\n",
    "X_unlabeled = np.random.rand(97, 2)\n",
    "X_combined = np.vstack([X_labeled, X_unlabeled])\n",
    "\n",
    "# Initialize unlabeled as -1 (unknown)\n",
    "y_combined = np.hstack([\n",
    "    y_labeled,\n",
    "    np.full(97, -1)  # -1 means unlabeled\n",
    "])\n",
    "\n",
    "# Label propagation: uses unlabeled data to improve\n",
    "model = LabelSpreading()\n",
    "model.fit(X_combined, y_combined)\n",
    "\n",
    "# Model learned from 3 labeled + 97 unlabeled samples!\n",
    "predictions = model.predict(X_unlabeled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Weak Supervision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use noisy/weak labels instead of manual annotation\n",
    "# Heuristics, rules, or cheap proxies for labels\n",
    "\n",
    "def weak_label_sentiment(text):\n",
    "    \"\"\"Weak labeling using simple rules\"\"\"\n",
    "    positive_words = {'great', 'amazing', 'wonderful', 'excellent', 'good'}\n",
    "    negative_words = {'bad', 'terrible', 'awful', 'horrible', 'poor'}\n",
    "    \n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    pos_count = sum(1 for word in positive_words if word in text_lower)\n",
    "    neg_count = sum(1 for word in negative_words if word in text_lower)\n",
    "    \n",
    "    if pos_count > neg_count:\n",
    "        return 1  # Positive\n",
    "    elif neg_count > pos_count:\n",
    "        return 0  # Negative\n",
    "    else:\n",
    "        return -1  # Uncertain\n",
    "\n",
    "# Automatically label huge dataset\n",
    "texts = [\"This is great!\", \"I hate it\", \"It's okay\"]\n",
    "weak_labels = [weak_label_sentiment(t) for t in texts]\n",
    "# Fast and cheap! But noisy...\n",
    "\n",
    "# Train model with noisy labels (handles noise)\n",
    "from snorkel.labeling import LabelingFunction\n",
    "from snorkel.labeling.model import LabelModel\n",
    "\n",
    "# Snorkel framework handles label aggregation and noise\n",
    "lfs = [  # Multiple weak labeling functions\n",
    "    weak_label_sentiment,\n",
    "    # Add more heuristics...\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Active Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intelligently select which samples to label\n",
    "# Focus labeling effort on most uncertain/informative samples\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "class ActiveLearner:\n",
    "    def __init__(self, base_model):\n",
    "        self.model = base_model\n",
    "        self.X_labeled = []\n",
    "        self.y_labeled = []\n",
    "        self.X_unlabeled = []\n",
    "    \n",
    "    def select_most_uncertain(self, n=10):\n",
    "        \"\"\"Select n most uncertain samples\"\"\"\n",
    "        probabilities = self.model.predict_proba(self.X_unlabeled)\n",
    "        \n",
    "        # Uncertainty = confidence closest to 0.5\n",
    "        uncertainty = 1 - np.max(probabilities, axis=1)\n",
    "        \n",
    "        # Select most uncertain\n",
    "        uncertain_indices = np.argsort(uncertainty)[-n:]\n",
    "        \n",
    "        return self.X_unlabeled[uncertain_indices]\n",
    "    \n",
    "    def add_labeled(self, X, y):\n",
    "        \"\"\"Add newly labeled samples\"\"\"\n",
    "        self.X_labeled.extend(X)\n",
    "        self.y_labeled.extend(y)\n",
    "    \n",
    "    def retrain(self):\n",
    "        \"\"\"Retrain with new labeled data\"\"\"\n",
    "        self.model.fit(self.X_labeled, self.y_labeled)\n",
    "\n",
    "# Active Learning Loop\n",
    "learner = ActiveLearner(RandomForestClassifier())\n",
    "\n",
    "# Start with 10 random labeled samples\n",
    "initial_indices = np.random.choice(1000, 10)\n",
    "learner.add_labeled(X[initial_indices], y[initial_indices])\n",
    "\n",
    "for iteration in range(10):  # 10 iterations\n",
    "    learner.retrain()\n",
    "    \n",
    "    # Select 10 most informative unlabeled samples\n",
    "    uncertain_samples = learner.select_most_uncertain(n=10)\n",
    "    \n",
    "    # Human labels these (expensive!)\n",
    "    human_labels = [human_label_this(s) for s in uncertain_samples]\n",
    "    \n",
    "    # Add to training data\n",
    "    learner.add_labeled(uncertain_samples, human_labels)\n",
    "    \n",
    "    print(f\"Iteration {iteration}: {learner.model.score(X_test, y_test):.3f}\")\n",
    "\n",
    "# With active learning:\n",
    "# - Label only 100 most informative samples instead of 1000\n",
    "# - Get better performance with less labeling\n",
    "# - 10x more efficient!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Crowdsourcing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use many cheap annotators instead of few expensive ones\n",
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "\n",
    "# 100 crowdworkers label same samples (cheap but noisy)\n",
    "# Aggregate their votes\n",
    "crowdworker_labels = [\n",
    "    [0, 1, 0, 1, 0],  # Worker 1's labels\n",
    "    [0, 1, 1, 1, 0],  # Worker 2's labels\n",
    "    [1, 1, 0, 1, 0],  # Worker 3's labels\n",
    "    # ... 97 more workers\n",
    "]\n",
    "\n",
    "# Simple aggregation: majority vote\n",
    "aggregated = mode(crowdworker_labels, axis=0)[0].flatten()\n",
    "# Result: [0, 1, 0, 1, 0]\n",
    "\n",
    "# More sophisticated: weight by worker reliability\n",
    "# Workers who agree more often get more weight\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "worker_reliability = np.array([\n",
    "    0.9,  # Worker 1 is 90% reliable\n",
    "    0.8,  # Worker 2 is 80% reliable\n",
    "    0.85, # Worker 3 is 85% reliable\n",
    "])\n",
    "\n",
    "weighted_votes = []\n",
    "for i in range(5):  # For each sample\n",
    "    votes = [\n",
    "        crowdworker_labels[j][i]\n",
    "        for j in range(3)\n",
    "    ]\n",
    "    weights = worker_reliability\n",
    "    \n",
    "    # Weighted average (0 or 1)\n",
    "    final_label = 1 if np.average(votes, weights=weights) > 0.5 else 0\n",
    "    weighted_votes.append(final_label)\n",
    "\n",
    "print(f\"Majority vote: {aggregated}\")\n",
    "print(f\"Weighted votes: {weighted_votes}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost-Benefit Analysis:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different data collection strategies\n",
    "strategies = {\n",
    "    'Manual Annotation': {\n",
    "        'cost_per_sample': 1.0,\n",
    "        'quality': 0.95,\n",
    "        'time_weeks': 50  # 10000 samples\n",
    "    },\n",
    "    'Crowdsourcing': {\n",
    "        'cost_per_sample': 0.1,\n",
    "        'quality': 0.85,\n",
    "        'time_weeks': 2  # Faster\n",
    "    },\n",
    "    'Data Augmentation': {\n",
    "        'cost_per_sample': 0.01,\n",
    "        'quality': 0.70,\n",
    "        'time_weeks': 1  # Very fast\n",
    "    },\n",
    "    'Transfer Learning': {\n",
    "        'cost_per_sample': 0.05,\n",
    "        'quality': 0.88,\n",
    "        'time_weeks': 1\n",
    "    }\n",
    "}\n",
    "\n",
    "n_samples_needed = 10000\n",
    "\n",
    "for strategy, specs in strategies.items():\n",
    "    cost = specs['cost_per_sample'] * n_samples_needed\n",
    "    quality = specs['quality']\n",
    "    time = specs['time_weeks']\n",
    "    \n",
    "    print(f\"\\n{strategy}:\")\n",
    "    print(f\"  Total Cost: ${cost:,.0f}\")\n",
    "    print(f\"  Quality: {quality*100:.0f}%\")\n",
    "    print(f\"  Time: {time} weeks\")\n",
    "    print(f\"  Cost/Quality ratio: {cost/quality:.0f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}