{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af11c7f2",
   "metadata": {},
   "source": [
    "### Data Analysis Process\n",
    "\n",
    "1. Asking Questions\n",
    "2. Dara Wrangling\n",
    "3. Exploratory Data Analysis\n",
    "4. Drawing Conclusions\n",
    "5. Communicating Results\n",
    "\n",
    "### 1. Asking Questions\n",
    "The first step in the data analysis process is to ask clear and focused questions. This involves identifying the problem you want to solve or the hypothesis you want to test. Good questions should be specific, measurable, and relevant to the data at hand.\n",
    "\n",
    "    1. What features will contribute to my analysis?\n",
    "    2. What features are not important for my analysis?\n",
    "    3. which of the features have a strong correlation with the target variable?\n",
    "    4. Do I need data processing?\n",
    "    5. What kind of feature manipulation/engaging is require?\n",
    "\n",
    "### Data Wrangling/Munging/Cleaning\n",
    "Data wrangling, also known as data cleaning, is the process of transforming and mapping raw data into a more usable format. This step is crucial for ensuring the quality and reliability of the data before analysis.\n",
    "\n",
    "    1. Handling missing values\n",
    "    2. Removing duplicates\n",
    "    3. Correcting inconsistencies\n",
    "    4. Normalizing or scaling data\n",
    "    5. Encoding categorical variables\n",
    "\n",
    "* Gathering Data \n",
    "    - CSV files, Databases, APIs\n",
    "* Assessing Data \n",
    "    - Understanding data quality, identifying missing values, and detecting outliers\n",
    "* Cleaning Data \n",
    "    - Handling missing values, correcting inconsistencies, and removing duplicates\n",
    "\n",
    "### Exporatory Data Analysis (EDA)\n",
    "Exploratory Data Analysis (EDA) is the process of analyzing data sets to summarize their main characteristics, often using visual methods. EDA helps to uncover patterns, spot anomalies, test hypotheses, and check assumptions.\n",
    "\n",
    "    1. Descriptive statistics\n",
    "    2. Data visualization\n",
    "    3. Identifying patterns and trends\n",
    "    4. Correlation analysis\n",
    "    5. Outlier detection\n",
    "\n",
    "### Drawing Conclusions\n",
    "Drawing conclusions involves interpreting the results of your analysis to answer the original questions posed. This step requires critical thinking and the ability to connect findings back to the broader context of the problem.\n",
    "\n",
    "    1. Summarizing key findings\n",
    "    2. Relating results to the original questions\n",
    "    3. Considering alternative explanations\n",
    "    4. Acknowledging limitations of the analysis\n",
    "    5. Suggesting next steps or further research\n",
    "\n",
    "* Machine Learing\n",
    "    - Supervised Learning\n",
    "    - Unsupervised Learning\n",
    "    - Model Evaluation\n",
    "* Inferential Statistics\n",
    "    - Hypothesis Testing\n",
    "    - Confidence Intervals\n",
    "* Descriptive Statistics\n",
    "    - Mean, Median, Mode\n",
    "    - Standard Deviation, Variance\n",
    "\n",
    "### Communicating Results/ Data Storytelling\n",
    "Communicating results effectively is essential for ensuring that stakeholders understand the insights derived from the data analysis. This step involves presenting findings in a clear and compelling manner.\n",
    "\n",
    "    1. Creating visualizations (charts, graphs, PPTs)\n",
    "    2. Writing reports or summaries\n",
    "    3. Presenting findings to stakeholders\n",
    "    4. Using storytelling techniques to engage the audience\n",
    "    5. Providing actionable recommendations based on the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0328d214",
   "metadata": {},
   "source": [
    "### Importing Data\n",
    "\n",
    "* Method 1: Using pandas\n",
    "\n",
    "    ```python\n",
    "    import pandas as pd\n",
    "    data = pd.read_csv('data.csv')\n",
    "    ```\n",
    "* Method 2: From an URL\n",
    "\n",
    "    ```python\n",
    "    import requests\n",
    "    from io import StringIO\n",
    "\n",
    "    url = \"https://example.com/data.csv\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    req = requests.get(url, headers=headers)\n",
    "    data = StringIO(req.text)\n",
    "\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv(data)\n",
    "    ```\n",
    "* Method 3: Using SQL\n",
    "\n",
    "    ```python\n",
    "    import sqlite3\n",
    "    conn = sqlite3.connect('database.db')\n",
    "    query = \"SELECT * FROM table_name\"\n",
    "    data = pd.read_sql_query(query, conn)\n",
    "    ```\n",
    "* Method 4: Using Excel\n",
    "\n",
    "    ```python\n",
    "    import pandas as pd\n",
    "    data = pd.read_excel('data.xlsx')\n",
    "    ```\n",
    "* Method 5: Using APIs\n",
    "\n",
    "    ```python   \n",
    "    import requests\n",
    "    response = requests.get('https://api.example.com/data')\n",
    "    data = response.json()\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa2a7a3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7d62fef",
   "metadata": {},
   "source": [
    "### Working with CSV files (CSV Comma Separated Values) usinf pandas\n",
    "\n",
    "* Reading a CSV file\n",
    "\n",
    "    ```python\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv('file.csv')\n",
    "    ```\n",
    "* Sep Parameter\n",
    "\n",
    "    ```python\n",
    "    df = pd.read_csv('file.csv', sep=';')  # for semicolon-separated values\n",
    "\n",
    "    df = pd.read_csv('file.tsv', sep='\\t')  # for tab-separated values\n",
    "\n",
    "    ```\n",
    "* Indec_col Parameter\n",
    "\n",
    "    ```python\n",
    "    df = pd.read_csv('file.csv', index_col='column Name')  # used for replacing the default index with a specific column name\n",
    "    ```\n",
    "* Header Parameter\n",
    "\n",
    "    ```python\n",
    "    df = pd.read_csv('file.csv', header=0)  # used to specify the row number to use as the column names\n",
    "    ```\n",
    "* use_cols Parameter\n",
    "\n",
    "    ```python\n",
    "    df = pd.read_csv('file.csv', usecols=['col1', 'col2'])  # used to select specific columns to read from the CSV file\n",
    "    ```\n",
    "* Squeeze Parameter\n",
    "\n",
    "    ```python\n",
    "    df = pd.read_csv('file.csv',usecols=['col1'], squeeze=True)  # used to convert a specific-column DataFrame into a Series\n",
    "    ```\n",
    "* Skiprows/nrows Parameter\n",
    "\n",
    "    ```python\n",
    "    df = pd.read_csv('file.csv', skiprows=[0,2])  # used to skip the first n rows of the CSV file\n",
    "\n",
    "    df = pd.read_csv('file.csv', nrows=100)  # used to read only the first n rows of the CSV file\n",
    "    ```\n",
    "* Encoding Parameter\n",
    "\n",
    "    ```python\n",
    "    df = pd.read_csv('file.csv', encoding='utf-8')  # used to specify the encoding of the CSV file\n",
    "    ```\n",
    "* Skip badlines Parameter\n",
    "\n",
    "    ```python\n",
    "    df = pd.read_csv('file.csv', error_bad_lines=False)  # used to skip lines with too many fields (deprecated, use on_bad_lines instead)\n",
    "    ```\n",
    "* Loading huge CSV files in chunks\n",
    "\n",
    "    ```python\n",
    "    chunk_size = 10000  # number of rows per chunk\n",
    "    chunks = pd.read_csv('large_file.csv', chunksize=chunk_size)\n",
    "\n",
    "    for chunk in chunks:\n",
    "        # process each chunk\n",
    "        print(chunk.head())\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae76a14",
   "metadata": {},
   "source": [
    "### Importing Excel files using pandas\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "df = pd.read_excel('file.xlsx', sheet_name='Sheet1')  # specify the sheet name\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16252fc8",
   "metadata": {},
   "source": [
    "### Importing txt files using pandas\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "df = pd.read_csv('file.txt', sep='\\t')  # for tab-separated values\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ac7802",
   "metadata": {},
   "source": [
    "### Importing JSON files using pandas\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "df = pd.read_json('file.json') \n",
    "```\n",
    "\n",
    "### Imporinting JSON files from URL\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "url = 'https://api.example.com/data.json'\n",
    "df = pd.read_json(url)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bd67f2",
   "metadata": {},
   "source": [
    "### Imporinting SQL files using pandas\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "conn = sqlite3.connect('database.db')\n",
    "query = \"SELECT * FROM table_name\"\n",
    "df = pd.read_sql_query(query, conn)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a27afc9",
   "metadata": {},
   "source": [
    "### Exporting Data as CSV using pandas\n",
    "\n",
    "```python   \n",
    "import pandas as pd\n",
    "df.to_csv('output.csv', index=False)  # index=False to avoid writing row indices\n",
    "```\n",
    "\n",
    "### Exporting Data as Excel using pandas\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "df.to_excel('output.xlsx', index=False)  # index=False to avoid writing row indices\n",
    "```\n",
    "\n",
    "### Exporting Data as JSON using pandas\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "df.to_json('output.json', orient='records', lines=True)\n",
    "```\n",
    "\n",
    "### Exporting Data to SQL using pandas\n",
    "\n",
    "```python   \n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "conn = sqlite3.connect('database.db')\n",
    "df.to_sql('table_name', conn, if_exists='replace', index=False)\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
